{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc1f03dd",
   "metadata": {},
   "source": [
    "## Feedforward ANNs\n",
    "\n",
    "Input is one side and the output is another. there is recurrence\n",
    "\n",
    "Repeating the single neuron\n",
    "\n",
    "Same ips can be fed to multiple different neurons calculating something different\n",
    "Neurons in one layer can acts as inps to another layer\n",
    "\n",
    "Multiple neurons per layers\n",
    "- call output of jth nueorn \n",
    "\n",
    "Feature Hierarchies\n",
    "\n",
    "- Each layer learns increasingly complex features\n",
    " \n",
    " Neural networks breaks down a problem into smaller sub problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08205f8",
   "metadata": {},
   "source": [
    "Large weights = important feature\n",
    "Small weights - Not important feature\n",
    "\n",
    "Linear neuron model not very expressive\n",
    "\n",
    "TO make the fitting line complicated - can add more input dimensions\n",
    "Make patter nonlinear\n",
    "\n",
    "Neuron model is the expression for line/plane\n",
    "\n",
    "Each neuron computes different nonlinear feature of input\n",
    "Nonlinear due to the use of sigmoid function\n",
    "\n",
    "Automatic Feature Engineering\n",
    "\n",
    "Ws and Bs are randomly initialised found iteratively using gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639bc10",
   "metadata": {},
   "source": [
    "## Sigmoid\n",
    "\n",
    "Sigmoid - 0 to 1 values.mimics biological neuron. makes neural network's decision boundary non linear\n",
    "\n",
    "Standardisation - inputs centered around 0 and approx the same range. Sigmoid op goes between 0 and 1 center being 0.5\n",
    "\n",
    "## Hyperbolic tangent\n",
    "\n",
    "Center is 0 rather than 0.5\n",
    "\n",
    "Vanishing Gradient problem - Depper the neural network, more terms have to be multiplied in. gradient due to chain rule of calculus\n",
    "\n",
    "Derivative of sigmoid very tiny. max val is 0.25\n",
    "\n",
    "Greedy layer wise pretaining is an old school training solution\n",
    "\n",
    "Solution - Use Relu (Rectified Linear unit)\n",
    "\n",
    "Relu advancements such as Leaky Relu - Slope of -1\n",
    "\n",
    "Softplus - Both softplus and ELU have vanishing gradients onthe left. \n",
    "\n",
    "\n",
    "## Multiclass Classification\n",
    "\n",
    "- OCR - Handwriting recognition (multiple possibilities) \n",
    "- Image Classficiation \n",
    "\n",
    "Final Layer  - Calculate value just before applying the final activation function \n",
    "- a(L) is a vector of size K \n",
    "Probability distribution over K distinct values. Probabilities must be non-negative(a>= 0)\n",
    "\n",
    "Softmax Function \n",
    "- Drops superscript(L) for convenience \n",
    "- function meets both of our requirments. \n",
    "\n",
    "Using softmax in TF(api) - tf.keras.layers.Dense(K, activation='softmax')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3cce1",
   "metadata": {},
   "source": [
    "## Images in ANN\n",
    "\n",
    "Colors are stored as RGB and the images are stored in Matrices\n",
    "For different colors, different proportions of RGB\n",
    "\n",
    "Grayscale Images - because each pixel value can only be black, white or array. they are stored in 2D arrays\n",
    "\n",
    "\n",
    "Dataset of images will be a 4 dimensional tensor N * w * h *c (C- channel)\n",
    "\n",
    "Process is called flattening to flatten the tensor to convert into N x D format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061df327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
