{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19106285",
   "metadata": {},
   "source": [
    "Regression - Trying to fit a line with a bunch of coordinates\n",
    "Classification - Both classification and regression - supervised learning\n",
    "Classification - Predict if smoker or not / Regression - Predict a salary\n",
    "Classification - Separate the coordinates with a line. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f8ddc9",
   "metadata": {},
   "source": [
    "### Linear Classification\n",
    "\n",
    "a) Load data (x, y)\n",
    "b) Instantiate model\n",
    "c) Train(fit) the model\n",
    "d) Evaluate (acccuracy)\n",
    "\n",
    "Line \n",
    "- y = mx + b\n",
    "For 2d classification\n",
    "- w1x1 + w2x2 + b = 0.  Horizontal axis - x1 and vertical axis - x2\n",
    "\n",
    "0 In deep learning, smooth differentiable funcs such as sigmoid is used\n",
    "\n",
    "- If probability > 50% - 1 or true else 0. This is sigmoid. Sigmoid - Logisitc func or logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b179d5eb",
   "metadata": {},
   "source": [
    "In Keras, used to add layer tf.keras.layers.Dense(output_size)\n",
    "\n",
    "To fit better you use a cost function.\n",
    "e.g. model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "Default in gradient descent is adam. Gradient descent - weight fitting\n",
    "\n",
    "\n",
    "### Training\n",
    "\n",
    "use -> model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)\n",
    "\n",
    "epochs are iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d51efb",
   "metadata": {},
   "source": [
    "## For Linear regressions- follow same steps as classification\n",
    "\n",
    "For LR use (no activation func)\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Input(shape=(1,)), tf.keras.layers.Dense(1)])\n",
    "\n",
    "compiling\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(0.001, 0.9), loss='mse'))\n",
    "SGD - Stochastic Gradient Descent\n",
    "\n",
    "\n",
    "### Learning Rate scheduling \n",
    "\n",
    "### Loss - \n",
    " we use mean squared error\n",
    " \n",
    " Accuracy cannot be used since no fixed target\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223f7e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4dd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
